{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede2daa3",
   "metadata": {},
   "source": [
    "# JAX\n",
    "\n",
    "This lecture provides a short introduction to [Google JAX](https://github.com/jax-ml/jax).\n",
    "\n",
    "JAX is a high-performance scientific computing library that provides\n",
    "\n",
    "- a [NumPy](https://en.wikipedia.org/wiki/NumPy)-like interface that can automatically parallelize across CPUs and GPUs,  \n",
    "- a just-in-time compiler for accelerating a large range of numerical\n",
    "  operations, and  \n",
    "- [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation).  \n",
    "\n",
    "\n",
    "Increasingly, JAX also maintains and provides [more specialized scientific\n",
    "computing routines](https://docs.jax.dev/en/latest/jax.scipy.html), such as those originally found in [SciPy](https://en.wikipedia.org/wiki/SciPy).\n",
    "\n",
    "In addition to what’s in Anaconda, this lecture will need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9e5f3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "!pip install jax quantecon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bd92e",
   "metadata": {},
   "source": [
    "# GPU\n",
    "\n",
    "This lecture was built using a machine with access to a GPU.\n",
    "\n",
    "[Google Colab](https://colab.research.google.com/) has a free tier with GPUs\n",
    "that you can access as follows:\n",
    "\n",
    "1. Click on the “play” icon top right  \n",
    "1. Select Colab  \n",
    "1. Set the runtime environment to include a GPU  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c613335",
   "metadata": {},
   "source": [
    "## JAX as a NumPy Replacement\n",
    "\n",
    "One of the attractive features of JAX is that, whenever possible, its array\n",
    "processing operations conform to the NumPy API.\n",
    "\n",
    "This means that, in many cases, we can use JAX as a drop-in NumPy replacement.\n",
    "\n",
    "Let’s look at the similarities and differences between JAX and NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462abbfe",
   "metadata": {},
   "source": [
    "### Similarities\n",
    "\n",
    "We’ll use the following imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d10e0d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import quantecon as qe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf00c2",
   "metadata": {},
   "source": [
    "In addition, we replace `import numpy as np` with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502bc15",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6076232",
   "metadata": {},
   "source": [
    "Now we can use `jnp` in place of `np` for the usual array operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99acf8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a = jnp.asarray((1.0, 3.2, -1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64d061",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e465e7d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(jnp.sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4cf963",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(jnp.mean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef3a7e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(jnp.dot(a, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe1dfd0",
   "metadata": {},
   "source": [
    "However, the array object `a` is not a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24917509",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943efbf",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4976261",
   "metadata": {},
   "source": [
    "Even scalar-valued maps on arrays return JAX arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917d42f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jnp.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0699483",
   "metadata": {},
   "source": [
    "Operations on higher dimensional arrays are also similar to NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0db40",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = jnp.ones((2, 2))\n",
    "B = jnp.identity(2)\n",
    "A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeaadf7",
   "metadata": {},
   "source": [
    "JAX’s array interface also provides the `linalg` subpackage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1fabe",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jnp.linalg.inv(B)   # Inverse of identity is identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559c1bf",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jnp.linalg.eigh(B)  # Computes eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985a8d6",
   "metadata": {},
   "source": [
    "### Differences\n",
    "\n",
    "Let’s now look at some differences between JAX and NumPy array operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49ebef",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "\n",
    "One difference between NumPy and JAX is that JAX uses 32 bit floats by default.\n",
    "\n",
    "This is because JAX is often used for GPU computing, and most GPU computations use 32 bit floats.\n",
    "\n",
    "Using 32 bit floats can lead to significant speed gains with small loss of precision.\n",
    "\n",
    "However, for some calculations precision matters.\n",
    "\n",
    "In these cases 64 bit floats can be enforced via the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfedaed",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c7313",
   "metadata": {},
   "source": [
    "Let’s check this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568f7d8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jnp.ones(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780fc59f",
   "metadata": {},
   "source": [
    "#### Immutability\n",
    "\n",
    "As a NumPy replacement, a more significant difference is that arrays are treated as **immutable**.\n",
    "\n",
    "For example, with NumPy we can write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90382d88",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.linspace(0, 1, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53d322",
   "metadata": {},
   "source": [
    "and then mutate the data in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e0889",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a[0] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beeb480",
   "metadata": {},
   "source": [
    "In JAX this fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63148ce5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a = jnp.linspace(0, 1, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf05774",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a[0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90017e8b",
   "metadata": {},
   "source": [
    "In line with immutability, JAX does not support inplace operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087beb50",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a = np.array((2, 1))\n",
    "a.sort()    # Unlike NumPy, does not mutate a\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0817b9e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a = jnp.array((2, 1))\n",
    "a_new = a.sort()   # Instead, the sort method returns a new sorted array\n",
    "a, a_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7601dc",
   "metadata": {},
   "source": [
    "The designers of JAX chose to make arrays immutable because JAX uses a\n",
    "[functional programming](https://en.wikipedia.org/wiki/Functional_programming) style.\n",
    "\n",
    "This design choice has important implications, which we explore next!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d9a01",
   "metadata": {},
   "source": [
    "#### A workaround\n",
    "\n",
    "We note that JAX does provide a version of in-place array modification\n",
    "using the [`at` method](https://docs.jax.dev/en/latest/_autosummary/jax.numpy.ndarray.at.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8fceb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a = jnp.linspace(0, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a3469",
   "metadata": {},
   "source": [
    "Applying `at[0].set(1)` returns a new copy of `a` with the first element set to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cca4c1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a = a.at[0].set(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50b62e",
   "metadata": {},
   "source": [
    "Obviously, there are downsides to using `at`:\n",
    "\n",
    "- The syntax is cumbersome and  \n",
    "- we want to avoid creating fresh arrays in memory every time we change a single value!  \n",
    "\n",
    "\n",
    "Hence, for the most part, we try to avoid this syntax.\n",
    "\n",
    "(Although it can in fact be efficient inside JIT-compiled functions – but let’s put this aside for now.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d569965",
   "metadata": {},
   "source": [
    "## Functional Programming\n",
    "\n",
    "From JAX’s documentation:\n",
    "\n",
    "*When walking about the countryside of Italy, the people will not hesitate to tell you that JAX has “una anima di pura programmazione funzionale”.*\n",
    "\n",
    "In other words, JAX assumes a functional programming style."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e498a87",
   "metadata": {},
   "source": [
    "### Pure functions\n",
    "\n",
    "The major implication is that JAX functions should be pure.\n",
    "\n",
    "[Pure functions](https://en.wikipedia.org/wiki/Pure_function) have the following characteristics:\n",
    "\n",
    "1. *Deterministic*  \n",
    "1. *No side effects*  \n",
    "\n",
    "\n",
    "[Deterministic](https://en.wikipedia.org/wiki/Deterministic_algorithm) means\n",
    "\n",
    "- Same input $ \\implies $ same output  \n",
    "- Outputs do not depend on global state  \n",
    "\n",
    "\n",
    "In particular, pure functions will always return the same result if invoked with the same inputs.\n",
    "\n",
    "[No side effects](https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29) means that the function\n",
    "\n",
    "- Won’t change global state  \n",
    "- Won’t modify data passed to the function (immutable data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e5263",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "Here’s an example of a *non-pure* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b5277",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "tax_rate = 0.1\n",
    "prices = [10.0, 20.0]\n",
    "\n",
    "def add_tax(prices):\n",
    "    for i, price in enumerate(prices):\n",
    "        prices[i] = price * (1 + tax_rate)\n",
    "    print('Post-tax prices: ', prices)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6444f10",
   "metadata": {},
   "source": [
    "This function fails to be pure because\n",
    "\n",
    "- side effects — it modifies the global variable `prices`  \n",
    "- non-deterministic — a change to the global variable `tax_rate` will modify\n",
    "  function outputs, even with the same input array `prices`.  \n",
    "\n",
    "\n",
    "Here’s a *pure* version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb9e53",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "tax_rate = 0.1\n",
    "prices = (10.0, 20.0)\n",
    "\n",
    "def add_tax_pure(prices, tax_rate):\n",
    "    new_prices = [price * (1 + tax_rate) for price in prices]\n",
    "    return new_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f5edb1",
   "metadata": {},
   "source": [
    "This pure version makes all dependencies explicit through function arguments, and doesn’t modify any external state.\n",
    "\n",
    "Now that we understand what pure functions are, let’s explore how JAX’s approach to random numbers maintains this purity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e63f12",
   "metadata": {},
   "source": [
    "## Random numbers\n",
    "\n",
    "Random numbers are rather different in JAX, compared to what you find in NumPy\n",
    "or Matlab.\n",
    "\n",
    "At first you might find the syntax rather verbose.\n",
    "\n",
    "But you will soon realize that the syntax and semantics are necessary in order\n",
    "to maintain the functional programming style we just discussed.\n",
    "\n",
    "Moreover, full control of random state is\n",
    "essential for parallel programming, such as when we want to run independent experiments along multiple threads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68535134",
   "metadata": {},
   "source": [
    "### Random number generation\n",
    "\n",
    "In JAX, the state of the random number generator is controlled explicitly.\n",
    "\n",
    "First we produce a key, which seeds the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8cbdb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c112807",
   "metadata": {},
   "source": [
    "Now we can use the key to generate some random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ec150",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "x = jax.random.normal(key, (3, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67318dbc",
   "metadata": {},
   "source": [
    "If we use the same key again, we initialize at the same seed, so the random numbers are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c15ec0",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jax.random.normal(key, (3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92795da1",
   "metadata": {},
   "source": [
    "To produce a (quasi-) independent draw, one option is to “split” the existing key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaaa9db",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe498a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jax.random.normal(key, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03204d68",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jax.random.normal(subkey, (3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f50fe3",
   "metadata": {},
   "source": [
    "This syntax will seem unusual for a NumPy or Matlab user — but will make a lot\n",
    "of sense when we progress to parallel programming.\n",
    "\n",
    "The function below produces `k` (quasi-) independent random `n x n` matrices using `split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf438b45",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def gen_random_matrices(key, n=2, k=3):\n",
    "    matrices = []\n",
    "    for _ in range(k):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        A = jax.random.uniform(subkey, (n, n))\n",
    "        matrices.append(A)\n",
    "        print(A)\n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f287b76",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "key = jax.random.PRNGKey(seed)\n",
    "matrices = gen_random_matrices(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f6c5e",
   "metadata": {},
   "source": [
    "We can also use `fold_in` when iterating in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a41795",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def gen_random_matrices(key, n=2, k=3):\n",
    "    matrices = []\n",
    "    for i in range(k):\n",
    "        step_key = jax.random.fold_in(key, i)\n",
    "        A = jax.random.uniform(step_key, (n, n))\n",
    "        matrices.append(A)\n",
    "        print(A)\n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff32b53",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(seed)\n",
    "matrices = gen_random_matrices(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a26bb",
   "metadata": {},
   "source": [
    "### Why explicit random state?\n",
    "\n",
    "Why does JAX require this somewhat verbose approach to random number generation?\n",
    "\n",
    "One reason is to maintain pure functions.\n",
    "\n",
    "Let’s see how random number generation relates to pure functions by comparing NumPy and JAX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3089ccf8",
   "metadata": {},
   "source": [
    "#### NumPy’s approach\n",
    "\n",
    "In NumPy, random number generation works by maintaining hidden global state.\n",
    "\n",
    "Each time we call a random function, this state is updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fd46c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "print(np.random.randn())   # Updates state of random number generator\n",
    "print(np.random.randn())   # Updates state of random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c83f2",
   "metadata": {},
   "source": [
    "Each call returns a different value, even though we’re calling the same function with the same inputs (no arguments).\n",
    "\n",
    "This function is *not pure* because:\n",
    "\n",
    "- It’s non-deterministic: same inputs (none, in this case) give different outputs  \n",
    "- It has side effects: it modifies the global random number generator state  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a38dc",
   "metadata": {},
   "source": [
    "#### JAX’s approach\n",
    "\n",
    "As we saw above, JAX takes a different approach, making randomness explicit through keys.\n",
    "\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f829a271",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def random_sum_jax(key):\n",
    "    key1, key2 = jax.random.split(key)\n",
    "    x = jax.random.normal(key1)\n",
    "    y = jax.random.normal(key2)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cf2bd",
   "metadata": {},
   "source": [
    "With the same key, we always get the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc7dbc",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(42)\n",
    "random_sum_jax(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ddb89a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "random_sum_jax(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc9a0c",
   "metadata": {},
   "source": [
    "To get new draws we need to supply a new key.\n",
    "\n",
    "The  function `random_sum_jax` is pure because:\n",
    "\n",
    "- It’s deterministic: same key always produces same output  \n",
    "- No side effects: no hidden state is modified  \n",
    "\n",
    "\n",
    "The explicitness of JAX brings significant benefits:\n",
    "\n",
    "- Reproducibility: Easy to reproduce results by reusing keys  \n",
    "- Parallelization: Each thread can have its own key without conflicts  \n",
    "- Debugging: No hidden state makes code easier to reason about  \n",
    "- JIT compatibility: The compiler can optimize pure functions more aggressively  \n",
    "\n",
    "\n",
    "The last point is expanded on in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee9d8e",
   "metadata": {},
   "source": [
    "## JIT compilation\n",
    "\n",
    "The JAX just-in-time (JIT) compiler accelerates execution by generating\n",
    "efficient machine code that varies with both task size and hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a6c6e0",
   "metadata": {},
   "source": [
    "### A simple example\n",
    "\n",
    "Let’s say we want to evaluate the cosine function at many points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985c536",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "n = 50_000_000\n",
    "x = np.linspace(0, 10, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18eee78",
   "metadata": {},
   "source": [
    "#### With NumPy\n",
    "\n",
    "Let’s try with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b76719",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = np.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a6ebf",
   "metadata": {},
   "source": [
    "And one more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16b1cc",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = np.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b7d39",
   "metadata": {},
   "source": [
    "Here NumPy uses a pre-built binary file, compiled from carefully written\n",
    "low-level code, for applying cosine to an array of floats.\n",
    "\n",
    "This binary file ships with NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63c8869",
   "metadata": {},
   "source": [
    "#### With JAX\n",
    "\n",
    "Now let’s try with JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a216d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "x = jnp.linspace(0, 10, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbffa79",
   "metadata": {},
   "source": [
    "Let’s time the same procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fded998",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = jnp.cos(x)\n",
    "    jax.block_until_ready(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a43fb0",
   "metadata": {},
   "source": [
    ">**Note**\n",
    ">\n",
    ">Here, in order to measure actual speed, we use the `block_until_ready` method\n",
    "to hold the interpreter until the results of the computation are returned.\n",
    "\n",
    "This is necessary because JAX uses asynchronous dispatch, which\n",
    "allows the Python interpreter to run ahead of numerical computations.\n",
    "\n",
    "For non-timed code, you can drop the line containing `block_until_ready`.\n",
    "\n",
    "And let’s time it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc7958",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = jnp.cos(x)\n",
    "    jax.block_until_ready(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb74623",
   "metadata": {},
   "source": [
    "On a GPU, this code runs much faster than its NumPy equivalent.\n",
    "\n",
    "Also, typically, the second run is faster than the first due to JIT compilation.\n",
    "\n",
    "This is because even built in functions like `jnp.cos` are JIT-compiled — and the\n",
    "first run includes compile time.\n",
    "\n",
    "Why would JAX want to JIT-compile built in functions like `jnp.cos` instead of\n",
    "just providing pre-compiled versions, like NumPy?\n",
    "\n",
    "The reason is that the JIT compiler wants to specialize on the *size* of the array\n",
    "being used (as well as the data type).\n",
    "\n",
    "The size matters for generating optimized code because efficient parallelization\n",
    "requires matching the size of the task to the available hardware.\n",
    "\n",
    "That’s why JAX waits to see the size of the array before compiling — which\n",
    "requires a JIT-compiled approach instead of supplying precompiled binaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226b050",
   "metadata": {},
   "source": [
    "#### Changing array sizes\n",
    "\n",
    "Here we change the input size and watch the runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc370be8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "x = jnp.linspace(0, 10, n + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de078d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = jnp.cos(x)\n",
    "    jax.block_until_ready(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8c642",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = jnp.cos(x)\n",
    "    jax.block_until_ready(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8271622d",
   "metadata": {},
   "source": [
    "Typically, the run time increases and then falls again (this will be more obvious on the GPU).\n",
    "\n",
    "This is because the JIT compiler specializes on array size to exploit\n",
    "parallelization — and hence generates fresh compiled code when the array size\n",
    "changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871bd78",
   "metadata": {},
   "source": [
    "### Evaluating a more complicated function\n",
    "\n",
    "Let’s try the same thing with a more complex function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b5775",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = np.cos(2 * x**2) + np.sqrt(np.abs(x)) + 2 * np.sin(x**4) - 0.1 * x**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33dda1d",
   "metadata": {},
   "source": [
    "#### With NumPy\n",
    "\n",
    "We’ll try first with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22aba5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "n = 50_000_000\n",
    "x = np.linspace(0, 10, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1398b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ecd852",
   "metadata": {},
   "source": [
    "#### With JAX\n",
    "\n",
    "Now let’s try again with JAX.\n",
    "\n",
    "As a first pass, we replace `np` with `jnp` throughout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d63c54",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = jnp.cos(2 * x**2) + jnp.sqrt(jnp.abs(x)) + 2 * jnp.sin(x**4) - x**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4bf39",
   "metadata": {},
   "source": [
    "Now let’s time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9140619",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "x = jnp.linspace(0, 10, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e93d5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = f(x)\n",
    "    jax.block_until_ready(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f0c9d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = f(x)\n",
    "    jax.block_until_ready(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ba9dd",
   "metadata": {},
   "source": [
    "The outcome is similar to the `cos` example — JAX is faster, especially on the second run after JIT compilation.\n",
    "\n",
    "Moreover, with JAX, we have another trick up our sleeve:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a236e0",
   "metadata": {},
   "source": [
    "### Compiling the Whole Function\n",
    "\n",
    "The JAX just-in-time (JIT) compiler can accelerate execution within functions by fusing linear\n",
    "algebra operations into a single optimized kernel.\n",
    "\n",
    "Let’s try this with the function `f`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9825a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "f_jax = jax.jit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf584d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = f_jax(x)\n",
    "    jax.block_until_ready(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514aa033",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    y = f_jax(x)\n",
    "    jax.block_until_ready(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965d486",
   "metadata": {},
   "source": [
    "The runtime has improved again — now because we fused all the operations,\n",
    "allowing the compiler to optimize more aggressively.\n",
    "\n",
    "For example, the compiler can eliminate multiple calls to the hardware\n",
    "accelerator and the creation of a number of intermediate arrays.\n",
    "\n",
    "Incidentally, a more common syntax when targeting a function for the JIT\n",
    "compiler is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2213657",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def f(x):\n",
    "    pass # put function body here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fbc468",
   "metadata": {},
   "source": [
    "### Compiling non-pure functions\n",
    "\n",
    "Now that we’ve seen how powerful JIT compilation can be, it’s important to understand its relationship with pure functions.\n",
    "\n",
    "While JAX will not usually throw errors when compiling impure functions, execution becomes unpredictable.\n",
    "\n",
    "Here’s an illustration of this fact, using global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c9478",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a = 1  # global\n",
    "\n",
    "@jax.jit\n",
    "def f(x):\n",
    "    return a + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3918b65",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "x = jnp.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb95af",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf0fd7",
   "metadata": {},
   "source": [
    "In the code above, the global value `a=1` is fused into the jitted function.\n",
    "\n",
    "Even if we change `a`, the output of `f` will not be affected — as long as the same compiled version is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db4cf4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "a = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32328a93",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608acf5c",
   "metadata": {},
   "source": [
    "Changing the dimension of the input triggers a fresh compilation of the function, at which time the change in the value of `a` takes effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83542aeb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "x = jnp.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0fefd9",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d52fb6",
   "metadata": {},
   "source": [
    "Moral of the story: write pure functions when using JAX!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac65e5",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Now we can see why both developers and compilers benefit from pure functions.\n",
    "\n",
    "We love pure functions because they\n",
    "\n",
    "- Help testing: each function can operate in isolation  \n",
    "- Promote deterministic behavior and hence reproducibility  \n",
    "- Prevent bugs that arise from mutating shared state  \n",
    "\n",
    "\n",
    "The compiler loves pure functions and functional programming because\n",
    "\n",
    "- Data dependencies are explicit, which helps with optimizing complex computations  \n",
    "- Pure functions are easier to differentiate (autodiff)  \n",
    "- Pure functions are easier to parallelize and optimize (don’t depend on shared mutable state)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ec394",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "\n",
    "JAX can use automatic differentiation to compute gradients.\n",
    "\n",
    "This can be extremely useful for optimization and solving nonlinear systems.\n",
    "\n",
    "We will see significant applications later in this lecture series.\n",
    "\n",
    "For now, here’s a very simple illustration involving the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f18ee0",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x**2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1adc0",
   "metadata": {},
   "source": [
    "Let’s take the derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3432f1c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "f_prime = jax.grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84791a89",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "f_prime(10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37335c4c",
   "metadata": {},
   "source": [
    "Let’s plot the function and derivative, noting that $ f'(x) = x $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13895ab",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x_grid = jnp.linspace(-4, 4, 200)\n",
    "ax.plot(x_grid, f(x_grid), label=\"$f$\")\n",
    "ax.plot(x_grid, [f_prime(x) for x in x_grid], label=\"$f'$\")\n",
    "ax.legend(loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282db80e",
   "metadata": {},
   "source": [
    "We defer further exploration of automatic differentiation with JAX until [Adventures with Autodiff](https://jax.quantecon.org/autodiff.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb575c4",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d048e82",
   "metadata": {},
   "source": [
    "## Exercise 14.1\n",
    "\n",
    "In the Exercise section of [our lecture on Numba](https://python-programming.quantecon.org/numba.html), we [used Monte Carlo to price a European call option](https://python-programming.quantecon.org/numba.html#numba_ex4).\n",
    "\n",
    "The code was accelerated by Numba-based multithreading.\n",
    "\n",
    "Try writing a version of this operation for JAX, using all the same\n",
    "parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845c3922",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "Here is one solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d2c2e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "M = 10_000_000\n",
    "\n",
    "n, β, K = 20, 0.99, 100\n",
    "μ, ρ, ν, S0, h0 = 0.0001, 0.1, 0.001, 10, 0\n",
    "\n",
    "@jax.jit\n",
    "def compute_call_price_jax(β=β,\n",
    "                           μ=μ,\n",
    "                           S0=S0,\n",
    "                           h0=h0,\n",
    "                           K=K,\n",
    "                           n=n,\n",
    "                           ρ=ρ,\n",
    "                           ν=ν,\n",
    "                           M=M,\n",
    "                           key=jax.random.PRNGKey(1)):\n",
    "\n",
    "    s = jnp.full(M, np.log(S0))\n",
    "    h = jnp.full(M, h0)\n",
    "\n",
    "    def update(i, loop_state):\n",
    "        s, h, key = loop_state\n",
    "        key, subkey = jax.random.split(key)\n",
    "        Z = jax.random.normal(subkey, (2, M))\n",
    "        s = s + μ + jnp.exp(h) * Z[0, :]\n",
    "        h = ρ * h + ν * Z[1, :]\n",
    "        new_loop_state = s, h, key\n",
    "        return new_loop_state\n",
    "\n",
    "    initial_loop_state = s, h, key\n",
    "    final_loop_state = jax.lax.fori_loop(0, n, update, initial_loop_state)\n",
    "    s, h, key = final_loop_state\n",
    "\n",
    "    expectation = jnp.mean(jnp.maximum(jnp.exp(s) - K, 0))\n",
    "\n",
    "    return β**n * expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4423f7bf",
   "metadata": {},
   "source": [
    ">**Note**\n",
    ">\n",
    ">We use `jax.lax.fori_loop` instead of a Python `for` loop.\n",
    "This allows JAX to compile the loop efficiently without unrolling it,\n",
    "which significantly reduces compilation time for large arrays.\n",
    "\n",
    "Let’s run it once to compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30526c55",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    compute_call_price_jax().block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ddbbe",
   "metadata": {},
   "source": [
    "And now let’s time it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8136cb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with qe.Timer():\n",
    "    compute_call_price_jax().block_until_ready()"
   ]
  }
 ],
 "metadata": {
  "date": 1766381926.5880122,
  "filename": "jax_intro.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "JAX"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}